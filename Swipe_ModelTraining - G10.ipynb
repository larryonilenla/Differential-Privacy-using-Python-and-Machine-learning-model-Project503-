{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDdeQb0Q7K7_"
      },
      "source": [
        "## Usefule Links:\n",
        "- Virtual environment and keras: https://www.tutorialspoint.com/keras/keras_installation.htm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "tFCVTFWV7K8U",
        "outputId": "12663405-f250-488c-a58e-bf0ce11c714c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>...</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.052478</td>\n",
              "      <td>0.277631</td>\n",
              "      <td>0.451259</td>\n",
              "      <td>0.718039</td>\n",
              "      <td>0.462785</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.018702</td>\n",
              "      <td>0.167556</td>\n",
              "      <td>-0.021220</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.000286</td>\n",
              "      <td>0.006156</td>\n",
              "      <td>0.000038</td>\n",
              "      <td>0.098039</td>\n",
              "      <td>0.175416</td>\n",
              "      <td>0.183196</td>\n",
              "      <td>0.083857</td>\n",
              "      <td>0.007032</td>\n",
              "      <td>0.183644</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.052112</td>\n",
              "      <td>0.329417</td>\n",
              "      <td>0.456423</td>\n",
              "      <td>0.707689</td>\n",
              "      <td>0.431129</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.018824</td>\n",
              "      <td>0.188321</td>\n",
              "      <td>-0.046427</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.001681</td>\n",
              "      <td>0.006563</td>\n",
              "      <td>0.000043</td>\n",
              "      <td>0.172549</td>\n",
              "      <td>0.161923</td>\n",
              "      <td>0.174437</td>\n",
              "      <td>0.012390</td>\n",
              "      <td>0.000154</td>\n",
              "      <td>0.172166</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.044798</td>\n",
              "      <td>0.246703</td>\n",
              "      <td>0.482247</td>\n",
              "      <td>0.682013</td>\n",
              "      <td>0.413386</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.023549</td>\n",
              "      <td>0.219466</td>\n",
              "      <td>-0.084152</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.003980</td>\n",
              "      <td>0.007612</td>\n",
              "      <td>0.000058</td>\n",
              "      <td>0.172549</td>\n",
              "      <td>0.165296</td>\n",
              "      <td>0.176905</td>\n",
              "      <td>0.015824</td>\n",
              "      <td>0.000250</td>\n",
              "      <td>0.179818</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.050101</td>\n",
              "      <td>0.292016</td>\n",
              "      <td>0.470626</td>\n",
              "      <td>0.711022</td>\n",
              "      <td>0.418269</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.019350</td>\n",
              "      <td>0.182533</td>\n",
              "      <td>-0.089321</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000438</td>\n",
              "      <td>0.009006</td>\n",
              "      <td>0.000081</td>\n",
              "      <td>0.149020</td>\n",
              "      <td>0.165296</td>\n",
              "      <td>0.178174</td>\n",
              "      <td>0.036672</td>\n",
              "      <td>0.001343</td>\n",
              "      <td>0.183644</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.048638</td>\n",
              "      <td>0.282665</td>\n",
              "      <td>0.438347</td>\n",
              "      <td>0.712347</td>\n",
              "      <td>0.447676</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.023968</td>\n",
              "      <td>0.151995</td>\n",
              "      <td>-0.024688</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.001410</td>\n",
              "      <td>0.007316</td>\n",
              "      <td>0.000054</td>\n",
              "      <td>0.125490</td>\n",
              "      <td>0.175416</td>\n",
              "      <td>0.184353</td>\n",
              "      <td>0.061493</td>\n",
              "      <td>0.003786</td>\n",
              "      <td>0.183644</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 34 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          1         2         3         4         5    6    7         8  \\\n",
              "0  0.052478  0.277631  0.451259  0.718039  0.462785  0.0  0.0  0.018702   \n",
              "1  0.052112  0.329417  0.456423  0.707689  0.431129  0.0  0.0  0.018824   \n",
              "2  0.044798  0.246703  0.482247  0.682013  0.413386  0.0  0.0  0.023549   \n",
              "3  0.050101  0.292016  0.470626  0.711022  0.418269  0.0  0.0  0.019350   \n",
              "4  0.048638  0.282665  0.438347  0.712347  0.447676  0.0  0.0  0.023968   \n",
              "\n",
              "          9        10  ...        25        26        27        28        29  \\\n",
              "0  0.167556 -0.021220  ... -0.000286  0.006156  0.000038  0.098039  0.175416   \n",
              "1  0.188321 -0.046427  ... -0.001681  0.006563  0.000043  0.172549  0.161923   \n",
              "2  0.219466 -0.084152  ... -0.003980  0.007612  0.000058  0.172549  0.165296   \n",
              "3  0.182533 -0.089321  ...  0.000438  0.009006  0.000081  0.149020  0.165296   \n",
              "4  0.151995 -0.024688  ... -0.001410  0.007316  0.000054  0.125490  0.175416   \n",
              "\n",
              "         30        31        32        33  Label  \n",
              "0  0.183196  0.083857  0.007032  0.183644      0  \n",
              "1  0.174437  0.012390  0.000154  0.172166      0  \n",
              "2  0.176905  0.015824  0.000250  0.179818      0  \n",
              "3  0.178174  0.036672  0.001343  0.183644      0  \n",
              "4  0.184353  0.061493  0.003786  0.183644      0  \n",
              "\n",
              "[5 rows x 34 columns]"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Read all data\n",
        "import csv\n",
        "import pandas as pd\n",
        "dataset=pd.read_csv('OversampledSwipeData.csv',index_col=0)\n",
        "dataset.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJ6zCcRoJBSj",
        "outputId": "3b5c9651-2166-4ad0-de1d-82bf7d1e0877"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(25800, 34)"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vtcvPN1l7K8h",
        "outputId": "c5e94289-305a-42be-8833-cea464d447ee"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Label\n",
              "0     300\n",
              "1     300\n",
              "2     300\n",
              "3     300\n",
              "4     300\n",
              "     ... \n",
              "81    300\n",
              "82    300\n",
              "83    300\n",
              "84    300\n",
              "85    300\n",
              "Name: Label, Length: 86, dtype: int64"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#replace the user ID by class name and count the number of sample in each class\n",
        "#dataset['Label'] = pd.factorize(dataset['Label'])[0]\n",
        "dataset.groupby(['Label'])['Label'].count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffvTQtrH7K8o",
        "outputId": "a2428e7b-1030-4d06-c93d-469d78d3b4c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total user in training dataset: 68\n",
            "Total user in auxiliary dataset: 18\n"
          ]
        }
      ],
      "source": [
        "#seperate the profile in two groups: (i) Training profile (0-67) 80.0\\%, and (ii) auxiliary profile (68-85) 20.0%\n",
        "totalUser= len(pd.unique(dataset['Label']))\n",
        "trainingData = dataset[dataset['Label'] < 68]\n",
        "auxilaryData = dataset[dataset['Label'] >= 68]\n",
        "print(\"Total user in training dataset:\", len(pd.unique(trainingData['Label'])))\n",
        "print(\"Total user in auxiliary dataset:\", len(pd.unique(auxilaryData['Label'])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "Z1iZ-P0c7K8s"
      },
      "outputs": [],
      "source": [
        "#Prepare the traning data for training and testing the model\n",
        "import tensorflow\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "X=trainingData.drop(columns=['Label'])\n",
        "y=trainingData['Label']\n",
        "\n",
        "Xtrain, Xval, ytrain, yval = train_test_split(X, y, test_size=0.2, random_state=22)\n",
        "#Xtrain, Xval, ytrain, yval = train_test_split(Xtrain, ytrain, test_size=0.2, random_state=22)\n",
        "\n",
        "ytrain = to_categorical(ytrain)\n",
        "yval = to_categorical(yval)\n",
        "#ytest = to_categorical(ytest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RR_H8-nz7K8v",
        "outputId": "1a368f4d-76be-4b8a-8451-618f9b37ea46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(16320, 33)\n",
            "(16320, 68)\n",
            "(4080, 33)\n",
            "(4080, 68)\n"
          ]
        }
      ],
      "source": [
        "print(Xtrain.shape)\n",
        "print(ytrain.shape)\n",
        "print(Xval.shape)\n",
        "print(yval.shape)\n",
        "#print(Xtest.shape)\n",
        "#print(ytest.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "mFKXheCd7K9r"
      },
      "outputs": [],
      "source": [
        "# import all necessary package for a neural network\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "#matplotlib inlineimport keras\n",
        "from keras.layers import Dense, Dropout, Input,Activation,Dropout, Flatten\n",
        "from keras.models import Model,Sequential\n",
        "from keras.datasets import mnist\n",
        "#from tqdm import tqdm\n",
        "#from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.optimizers import Adam\n",
        "#import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "vQeWRxpf7K93"
      },
      "outputs": [],
      "source": [
        "#define optimizers for neural network\n",
        "from keras.optimizers import SGD, RMSprop, Adam\n",
        "def adam_optimizer():\n",
        "    return Adam(lr=0.0002, beta_1=0.5)\n",
        "\n",
        "def RMSprop_optimizer():\n",
        "    return RMSprop(lr=0.001, rho=0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bpyiok1O7K96",
        "outputId": "df7f7cc0-ce69-48ec-de0e-b7dbb6d7d438"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_50 (Dense)            (None, 128)               4352      \n",
            "                                                                 \n",
            " batch_normalization_41 (Bat  (None, 128)              512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_41 (Activation)  (None, 128)               0         \n",
            "                                                                 \n",
            " dropout_20 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_51 (Dense)            (None, 256)               33024     \n",
            "                                                                 \n",
            " batch_normalization_42 (Bat  (None, 256)              1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_42 (Activation)  (None, 256)               0         \n",
            "                                                                 \n",
            " dropout_21 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_52 (Dense)            (None, 512)               131584    \n",
            "                                                                 \n",
            " batch_normalization_43 (Bat  (None, 512)              2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_43 (Activation)  (None, 512)               0         \n",
            "                                                                 \n",
            " dropout_22 (Dropout)        (None, 512)               0         \n",
            "                                                                 \n",
            " dense_53 (Dense)            (None, 256)               131328    \n",
            "                                                                 \n",
            " batch_normalization_44 (Bat  (None, 256)              1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_44 (Activation)  (None, 256)               0         \n",
            "                                                                 \n",
            " dropout_23 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_54 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " batch_normalization_45 (Bat  (None, 128)              512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_45 (Activation)  (None, 128)               0         \n",
            "                                                                 \n",
            " dropout_24 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_55 (Dense)            (None, 68)                8772      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 347,076\n",
            "Trainable params: 344,516\n",
            "Non-trainable params: 2,560\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\mdmor\\OneDrive\\Documents\\GitHub\\ModelDataProtection\\.venv\\Lib\\site-packages\\keras\\optimizers\\legacy\\rmsprop.py:143: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "#neural network architecture for model training\n",
        "\n",
        "def create_classifier(release=False,totalClass=68):\n",
        "  classifier = Sequential()\n",
        "  classifier.add(Dense(128, input_dim=33))\n",
        "  classifier.add(BatchNormalization())\n",
        "  classifier.add(Activation('relu'))\n",
        "  classifier.add(Dropout(0.1))\n",
        "\n",
        "  #classifier.add(Dense(256))\n",
        "  #classifier.add(BatchNormalization())\n",
        "  #classifier.add(Activation('relu'))\n",
        "\n",
        "  classifier.add(Dense(256))\n",
        "  classifier.add(BatchNormalization())\n",
        "  classifier.add(Activation('relu'))\n",
        "  classifier.add(Dropout(0.1))\n",
        "\n",
        "  classifier.add(Dense(512))\n",
        "  classifier.add(BatchNormalization())\n",
        "  classifier.add(Activation('relu'))\n",
        "  classifier.add(Dropout(0.1))\n",
        "\n",
        "  classifier.add(Dense(256))\n",
        "  classifier.add(BatchNormalization())\n",
        "  classifier.add(Activation('relu'))\n",
        "  classifier.add(Dropout(0.1))\n",
        "\n",
        "  classifier.add(Dense(128))\n",
        "  classifier.add(BatchNormalization())\n",
        "  classifier.add(Activation('relu'))\n",
        "  classifier.add(Dropout(0.1))\n",
        "\n",
        "  #if release:\n",
        "  classifier.add(Dense(totalClass, activation='softmax'))\n",
        "  #else:\n",
        "  #   classifier.add(Dense(Tuser))\n",
        "  #np.log_softmax_v2(a, axis=axis)\n",
        "  #classifier.add(F.softmax(a, dim=1))\n",
        "\n",
        "  classifier.compile(loss='categorical_crossentropy', optimizer=RMSprop_optimizer(),metrics=['accuracy'])\n",
        "  return classifier\n",
        "\n",
        "Clasf=create_classifier()\n",
        "Clasf.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eg9_dAIv7K-D",
        "outputId": "06df0b30-c9f8-4156-bbbe-32603a5cbaae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "255/255 [==============================] - 6s 11ms/step - loss: 1.8005 - accuracy: 0.5104 - val_loss: 3.3209 - val_accuracy: 0.1444 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "255/255 [==============================] - 2s 10ms/step - loss: 0.9453 - accuracy: 0.6971 - val_loss: 0.9957 - val_accuracy: 0.6657 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "255/255 [==============================] - 2s 10ms/step - loss: 0.7727 - accuracy: 0.7456 - val_loss: 0.6005 - val_accuracy: 0.8015 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "255/255 [==============================] - 2s 10ms/step - loss: 0.6975 - accuracy: 0.7657 - val_loss: 0.5262 - val_accuracy: 0.8152 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "255/255 [==============================] - 2s 9ms/step - loss: 0.6432 - accuracy: 0.7842 - val_loss: 0.5077 - val_accuracy: 0.8211 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "255/255 [==============================] - 2s 10ms/step - loss: 0.6122 - accuracy: 0.7940 - val_loss: 0.4478 - val_accuracy: 0.8471 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "255/255 [==============================] - 2s 10ms/step - loss: 0.5580 - accuracy: 0.8107 - val_loss: 0.4318 - val_accuracy: 0.8461 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "255/255 [==============================] - 2s 10ms/step - loss: 0.5475 - accuracy: 0.8140 - val_loss: 0.4203 - val_accuracy: 0.8583 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "255/255 [==============================] - 2s 10ms/step - loss: 0.5165 - accuracy: 0.8268 - val_loss: 0.3626 - val_accuracy: 0.8745 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "255/255 [==============================] - 3s 10ms/step - loss: 0.4951 - accuracy: 0.8307 - val_loss: 0.3512 - val_accuracy: 0.8833 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "255/255 [==============================] - 2s 10ms/step - loss: 0.4704 - accuracy: 0.8419 - val_loss: 0.3607 - val_accuracy: 0.8833 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "255/255 [==============================] - 2s 9ms/step - loss: 0.4567 - accuracy: 0.8428 - val_loss: 0.3420 - val_accuracy: 0.8821 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "255/255 [==============================] - 2s 9ms/step - loss: 0.4314 - accuracy: 0.8517 - val_loss: 0.3471 - val_accuracy: 0.8797 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "255/255 [==============================] - 2s 9ms/step - loss: 0.4206 - accuracy: 0.8586 - val_loss: 0.3678 - val_accuracy: 0.8618 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "255/255 [==============================] - 2s 9ms/step - loss: 0.4013 - accuracy: 0.8627 - val_loss: 0.3140 - val_accuracy: 0.8882 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "255/255 [==============================] - 3s 13ms/step - loss: 0.4073 - accuracy: 0.8618 - val_loss: 0.3016 - val_accuracy: 0.8968 - lr: 0.0010\n",
            "Epoch 17/50\n",
            "255/255 [==============================] - 3s 11ms/step - loss: 0.3890 - accuracy: 0.8632 - val_loss: 0.2980 - val_accuracy: 0.8978 - lr: 0.0010\n",
            "Epoch 18/50\n",
            "255/255 [==============================] - 4s 15ms/step - loss: 0.3825 - accuracy: 0.8680 - val_loss: 0.2615 - val_accuracy: 0.9125 - lr: 0.0010\n",
            "Epoch 19/50\n",
            "255/255 [==============================] - 4s 15ms/step - loss: 0.3724 - accuracy: 0.8709 - val_loss: 0.2971 - val_accuracy: 0.8966 - lr: 0.0010\n",
            "Epoch 20/50\n",
            "255/255 [==============================] - 4s 16ms/step - loss: 0.3592 - accuracy: 0.8767 - val_loss: 0.2944 - val_accuracy: 0.8985 - lr: 0.0010\n",
            "Epoch 21/50\n",
            "255/255 [==============================] - 4s 15ms/step - loss: 0.3513 - accuracy: 0.8771 - val_loss: 0.3045 - val_accuracy: 0.8902 - lr: 0.0010\n",
            "Epoch 22/50\n",
            "255/255 [==============================] - 4s 14ms/step - loss: 0.3491 - accuracy: 0.8770 - val_loss: 0.2474 - val_accuracy: 0.9100 - lr: 0.0010\n",
            "Epoch 23/50\n",
            "251/255 [============================>.] - ETA: 0s - loss: 0.3365 - accuracy: 0.8833\n",
            "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "255/255 [==============================] - 3s 14ms/step - loss: 0.3357 - accuracy: 0.8836 - val_loss: 0.2887 - val_accuracy: 0.9066 - lr: 0.0010\n",
            "Epoch 24/50\n",
            "255/255 [==============================] - 3s 13ms/step - loss: 0.2835 - accuracy: 0.9005 - val_loss: 0.1905 - val_accuracy: 0.9402 - lr: 5.0000e-04\n",
            "Epoch 25/50\n",
            "255/255 [==============================] - 4s 17ms/step - loss: 0.2686 - accuracy: 0.9058 - val_loss: 0.1880 - val_accuracy: 0.9377 - lr: 5.0000e-04\n",
            "Epoch 26/50\n",
            "255/255 [==============================] - 4s 16ms/step - loss: 0.2580 - accuracy: 0.9091 - val_loss: 0.1791 - val_accuracy: 0.9392 - lr: 5.0000e-04\n",
            "Epoch 27/50\n",
            "255/255 [==============================] - 4s 17ms/step - loss: 0.2544 - accuracy: 0.9111 - val_loss: 0.1805 - val_accuracy: 0.9397 - lr: 5.0000e-04\n",
            "Epoch 28/50\n",
            "255/255 [==============================] - 5s 20ms/step - loss: 0.2636 - accuracy: 0.9072 - val_loss: 0.1695 - val_accuracy: 0.9431 - lr: 5.0000e-04\n",
            "Epoch 29/50\n",
            "255/255 [==============================] - 5s 20ms/step - loss: 0.2493 - accuracy: 0.9121 - val_loss: 0.1923 - val_accuracy: 0.9368 - lr: 5.0000e-04\n",
            "Epoch 30/50\n",
            "255/255 [==============================] - 5s 19ms/step - loss: 0.2511 - accuracy: 0.9114 - val_loss: 0.1633 - val_accuracy: 0.9453 - lr: 5.0000e-04\n",
            "Epoch 31/50\n",
            "255/255 [==============================] - 4s 16ms/step - loss: 0.2449 - accuracy: 0.9121 - val_loss: 0.1794 - val_accuracy: 0.9373 - lr: 5.0000e-04\n",
            "Epoch 32/50\n",
            "255/255 [==============================] - 5s 20ms/step - loss: 0.2408 - accuracy: 0.9135 - val_loss: 0.1750 - val_accuracy: 0.9419 - lr: 5.0000e-04\n",
            "Epoch 33/50\n",
            "255/255 [==============================] - 5s 18ms/step - loss: 0.2477 - accuracy: 0.9104 - val_loss: 0.1719 - val_accuracy: 0.9417 - lr: 5.0000e-04\n",
            "Epoch 34/50\n",
            "255/255 [==============================] - 4s 17ms/step - loss: 0.2399 - accuracy: 0.9133 - val_loss: 0.1783 - val_accuracy: 0.9387 - lr: 5.0000e-04\n",
            "Epoch 35/50\n",
            "252/255 [============================>.] - ETA: 0s - loss: 0.2352 - accuracy: 0.9177\n",
            "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "255/255 [==============================] - 5s 18ms/step - loss: 0.2363 - accuracy: 0.9170 - val_loss: 0.1561 - val_accuracy: 0.9453 - lr: 5.0000e-04\n",
            "Epoch 36/50\n",
            "255/255 [==============================] - 5s 18ms/step - loss: 0.2175 - accuracy: 0.9220 - val_loss: 0.1458 - val_accuracy: 0.9537 - lr: 2.5000e-04\n",
            "Epoch 37/50\n",
            "255/255 [==============================] - 5s 18ms/step - loss: 0.2026 - accuracy: 0.9297 - val_loss: 0.1431 - val_accuracy: 0.9544 - lr: 2.5000e-04\n",
            "Epoch 38/50\n",
            "255/255 [==============================] - 5s 18ms/step - loss: 0.2080 - accuracy: 0.9259 - val_loss: 0.1359 - val_accuracy: 0.9539 - lr: 2.5000e-04\n",
            "Epoch 39/50\n",
            "255/255 [==============================] - 5s 18ms/step - loss: 0.1986 - accuracy: 0.9290 - val_loss: 0.1308 - val_accuracy: 0.9559 - lr: 2.5000e-04\n",
            "Epoch 40/50\n",
            "255/255 [==============================] - 4s 16ms/step - loss: 0.1992 - accuracy: 0.9306 - val_loss: 0.1382 - val_accuracy: 0.9537 - lr: 2.5000e-04\n",
            "Epoch 41/50\n",
            "255/255 [==============================] - 5s 19ms/step - loss: 0.1899 - accuracy: 0.9322 - val_loss: 0.1344 - val_accuracy: 0.9537 - lr: 2.5000e-04\n",
            "Epoch 42/50\n",
            "255/255 [==============================] - 5s 18ms/step - loss: 0.1918 - accuracy: 0.9319 - val_loss: 0.1335 - val_accuracy: 0.9510 - lr: 2.5000e-04\n",
            "Epoch 43/50\n",
            "255/255 [==============================] - 5s 18ms/step - loss: 0.1876 - accuracy: 0.9345 - val_loss: 0.1273 - val_accuracy: 0.9581 - lr: 2.5000e-04\n",
            "Epoch 44/50\n",
            "255/255 [==============================] - 5s 19ms/step - loss: 0.1886 - accuracy: 0.9325 - val_loss: 0.1247 - val_accuracy: 0.9571 - lr: 2.5000e-04\n",
            "Epoch 45/50\n",
            "255/255 [==============================] - 5s 18ms/step - loss: 0.1924 - accuracy: 0.9298 - val_loss: 0.1301 - val_accuracy: 0.9605 - lr: 2.5000e-04\n",
            "Epoch 46/50\n",
            "255/255 [==============================] - 5s 18ms/step - loss: 0.1867 - accuracy: 0.9333 - val_loss: 0.1395 - val_accuracy: 0.9556 - lr: 2.5000e-04\n",
            "Epoch 47/50\n",
            "255/255 [==============================] - 5s 19ms/step - loss: 0.1881 - accuracy: 0.9330 - val_loss: 0.1319 - val_accuracy: 0.9586 - lr: 2.5000e-04\n",
            "Epoch 48/50\n",
            "255/255 [==============================] - 5s 19ms/step - loss: 0.1838 - accuracy: 0.9336 - val_loss: 0.1263 - val_accuracy: 0.9564 - lr: 2.5000e-04\n",
            "Epoch 49/50\n",
            "255/255 [==============================] - 4s 18ms/step - loss: 0.1822 - accuracy: 0.9357 - val_loss: 0.1288 - val_accuracy: 0.9576 - lr: 2.5000e-04\n",
            "Epoch 50/50\n",
            "254/255 [============================>.] - ETA: 0s - loss: 0.1819 - accuracy: 0.9358\n",
            "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "255/255 [==============================] - 5s 18ms/step - loss: 0.1818 - accuracy: 0.9358 - val_loss: 0.1185 - val_accuracy: 0.9600 - lr: 2.5000e-04\n"
          ]
        }
      ],
      "source": [
        "#Train the classifier seperately for black-box attack\n",
        "import keras\n",
        "\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, UpSampling2D\n",
        "from keras.optimizers import SGD, RMSprop, Adam\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', patience=5, verbose=1, factor=0.5,min_lr=0.0001)\n",
        "callbacks_list = [learning_rate_reduction]\n",
        "\n",
        "Classfier2= create_classifier(True,68)\n",
        "\n",
        "#------Comment will start from here\n",
        "lossc='categorical_crossentropy'\n",
        "#optimizerc=RMSprop(learning_rate=0.0001, rho=0.9)\n",
        "optimizerc=Adam(learning_rate=0.001)\n",
        "Classfier2.compile(loss=lossc, optimizer=optimizerc,metrics=['accuracy'])\n",
        "#------Comments will end from here\n",
        "historyc2 =  Classfier2.fit(Xtrain, ytrain, batch_size=64, epochs=50, validation_data=(Xval, yval),verbose=1, callbacks=callbacks_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "oLCDk2Rl7K-Z",
        "outputId": "86033674-222d-48e5-d1de-ca52f16fe374"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'epochs')"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Plot the classifier loss and accuracy curves for training and validation data\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(historyc2.history['accuracy'], color='b', label=\"Training accuracy\")\n",
        "plt.plot(historyc2.history['val_accuracy'], color='r',label=\"Validation accuracy\")\n",
        "legend = plt.legend(loc='best', shadow=True)\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epochs')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>...</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2595</th>\n",
              "      <td>0.042055</td>\n",
              "      <td>0.373291</td>\n",
              "      <td>0.462234</td>\n",
              "      <td>0.672240</td>\n",
              "      <td>0.460185</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.007363</td>\n",
              "      <td>0.181142</td>\n",
              "      <td>-0.057993</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000146</td>\n",
              "      <td>0.017546</td>\n",
              "      <td>0.000308</td>\n",
              "      <td>0.176471</td>\n",
              "      <td>0.182163</td>\n",
              "      <td>0.180288</td>\n",
              "      <td>0.031583</td>\n",
              "      <td>0.000997</td>\n",
              "      <td>0.187470</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3984</th>\n",
              "      <td>0.038581</td>\n",
              "      <td>0.480622</td>\n",
              "      <td>0.728615</td>\n",
              "      <td>0.953126</td>\n",
              "      <td>0.664928</td>\n",
              "      <td>0.034667</td>\n",
              "      <td>0.024510</td>\n",
              "      <td>0.003954</td>\n",
              "      <td>0.307242</td>\n",
              "      <td>-0.252209</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.022077</td>\n",
              "      <td>0.034743</td>\n",
              "      <td>0.001207</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.860215</td>\n",
              "      <td>0.943739</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.975610</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6137</th>\n",
              "      <td>0.068385</td>\n",
              "      <td>0.357468</td>\n",
              "      <td>0.628147</td>\n",
              "      <td>0.658977</td>\n",
              "      <td>0.675978</td>\n",
              "      <td>0.045326</td>\n",
              "      <td>0.029412</td>\n",
              "      <td>0.004798</td>\n",
              "      <td>0.133935</td>\n",
              "      <td>-0.006750</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.000243</td>\n",
              "      <td>0.009306</td>\n",
              "      <td>0.000087</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.860215</td>\n",
              "      <td>0.943739</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.975610</td>\n",
              "      <td>51</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6479</th>\n",
              "      <td>0.034741</td>\n",
              "      <td>0.249940</td>\n",
              "      <td>0.421155</td>\n",
              "      <td>0.462863</td>\n",
              "      <td>0.392526</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.030944</td>\n",
              "      <td>0.161029</td>\n",
              "      <td>-0.068421</td>\n",
              "      <td>...</td>\n",
              "      <td>0.002685</td>\n",
              "      <td>0.018482</td>\n",
              "      <td>0.000342</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.860215</td>\n",
              "      <td>0.943739</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.975610</td>\n",
              "      <td>53</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>0.080271</td>\n",
              "      <td>0.253895</td>\n",
              "      <td>0.510652</td>\n",
              "      <td>0.724922</td>\n",
              "      <td>0.429636</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.009380</td>\n",
              "      <td>0.122974</td>\n",
              "      <td>-0.096867</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000560</td>\n",
              "      <td>0.007207</td>\n",
              "      <td>0.000052</td>\n",
              "      <td>0.062745</td>\n",
              "      <td>0.168670</td>\n",
              "      <td>0.172760</td>\n",
              "      <td>0.097554</td>\n",
              "      <td>0.009515</td>\n",
              "      <td>0.175992</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 34 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             1         2         3         4         5         6         7  \\\n",
              "2595  0.042055  0.373291  0.462234  0.672240  0.460185  0.000000  0.000000   \n",
              "3984  0.038581  0.480622  0.728615  0.953126  0.664928  0.034667  0.024510   \n",
              "6137  0.068385  0.357468  0.628147  0.658977  0.675978  0.045326  0.029412   \n",
              "6479  0.034741  0.249940  0.421155  0.462863  0.392526  0.000000  0.000000   \n",
              "39    0.080271  0.253895  0.510652  0.724922  0.429636  0.000000  0.000000   \n",
              "\n",
              "             8         9        10  ...        25        26        27  \\\n",
              "2595  0.007363  0.181142 -0.057993  ...  0.000146  0.017546  0.000308   \n",
              "3984  0.003954  0.307242 -0.252209  ... -0.022077  0.034743  0.001207   \n",
              "6137  0.004798  0.133935 -0.006750  ... -0.000243  0.009306  0.000087   \n",
              "6479  0.030944  0.161029 -0.068421  ...  0.002685  0.018482  0.000342   \n",
              "39    0.009380  0.122974 -0.096867  ...  0.000560  0.007207  0.000052   \n",
              "\n",
              "            28        29        30        31        32        33  Label  \n",
              "2595  0.176471  0.182163  0.180288  0.031583  0.000997  0.187470     21  \n",
              "3984  1.000000  0.860215  0.943739  0.000000  0.000000  0.975610     33  \n",
              "6137  1.000000  0.860215  0.943739  0.000000  0.000000  0.975610     51  \n",
              "6479  1.000000  0.860215  0.943739  0.000000  0.000000  0.975610     53  \n",
              "39    0.062745  0.168670  0.172760  0.097554  0.009515  0.175992      0  \n",
              "\n",
              "[5 rows x 34 columns]"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#valid test data\n",
        "import csv\n",
        "import pandas as pd\n",
        "testdataset=pd.read_csv('Dataset/SwipeDatatest.csv',index_col=0)\n",
        "testdataset = testdataset[testdataset['Label'] < 68]\n",
        "Xtest=testdataset.drop(columns=['Label'])\n",
        "ytest=testdataset['Label']\n",
        "ytest = to_categorical(ytest)\n",
        "\n",
        "testdataset.head()\n",
        "#Xtest.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60OnWGGQ7K-b",
        "outputId": "6d91f20a-176b-410c-e2a5-ec3d3b15465f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "52/52 [==============================] - 1s 4ms/step - loss: 0.6762 - accuracy: 0.8170\n",
            "Loss: 0.6761940121650696\n",
            "Accuracy: 0.8169615864753723\n"
          ]
        }
      ],
      "source": [
        "#Performance of the classifier for valid test data\n",
        "Classfier2.compile(loss='categorical_crossentropy', optimizer=Adam(),metrics=['accuracy'])\n",
        "loss, accuracy = Classfier2.evaluate(Xtest, ytest)\n",
        "#print('Test score:', score)\n",
        "print('Loss:', loss)\n",
        "print('Accuracy:', accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n"
          ]
        }
      ],
      "source": [
        "#invalid test data\n",
        "import csv\n",
        "import pandas as pd\n",
        "testdataset=pd.read_csv('Dataset/SwipeDatatest.csv',index_col=0)\n",
        "testdataset = testdataset[testdataset['Label'] >= 68]\n",
        "Xtest=testdataset.drop(columns=['Label'])\n",
        "ytest = np.random.randint(0, 68, size=Xtest.shape[0])\n",
        "ytest = pd.DataFrame(ytest, columns=['random_numbers'])\n",
        "#ytest=testdataset['Label']\n",
        "print(type(ytest))\n",
        "ytest = to_categorical(ytest)\n",
        "\n",
        "#testdataset.head()\n",
        "#Xtest.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "14/14 [==============================] - 0s 2ms/step - loss: 14.3318 - accuracy: 0.0094\n",
            "Loss: 14.331758499145508\n",
            "Accuracy: 0.009411764331161976\n"
          ]
        }
      ],
      "source": [
        "#Performance of the classifier for valid test data\n",
        "Classfier2.compile(loss='categorical_crossentropy', optimizer=Adam(),metrics=['accuracy'])\n",
        "loss, accuracy = Classfier2.evaluate(Xtest, ytest)\n",
        "#print('Test score:', score)\n",
        "print('Loss:', loss)\n",
        "print('Accuracy:', accuracy)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
